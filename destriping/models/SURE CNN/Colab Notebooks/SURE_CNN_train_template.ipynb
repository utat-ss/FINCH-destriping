{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45391,
     "status": "ok",
     "timestamp": 1665765249146,
     "user": {
      "displayName": "Punyaphat Sukcharoenchaikul",
      "userId": "05777821768464563273"
     },
     "user_tz": 240
    },
    "id": "OaCTY3_L2iy-",
    "outputId": "624ba7ab-9508-4de0-ea5b-0e5709efaeb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting import_ipynb\n",
      "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (5.7.0)\n",
      "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (7.9.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.6.1)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 3.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.0.10)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (5.1.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (57.4.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (2.16.2)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.11.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (5.0.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.3.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import_ipynb) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import_ipynb) (3.9.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.10.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n",
      "Installing collected packages: jedi, import-ipynb\n",
      "Successfully installed import-ipynb-0.1.4 jedi-0.18.1\n",
      "Mounted at /content/drive\n",
      "/content/drive/Shareddrives/Space Systems Division/Teams/FINCH/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Noise Functions\n",
      "importing Jupyter notebook from apply_stripes.ipynb\n",
      "/content/drive/Shareddrives/Space Systems Division/Teams/FINCH/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Destriping Models\n",
      "importing Jupyter notebook from noise_estimation.ipynb\n",
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "/content/drive/Shareddrives/Space Systems Division/Teams/FINCH/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Destriping Models/SURE CNN/Colab Notebooks/HSI_Denoising_SURE_CNN-master\n"
     ]
    }
   ],
   "source": [
    "# Imports not from the google drive\n",
    "# stdlib\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# external\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!pip install import_ipynb\n",
    "# external\n",
    "import import_ipynb\n",
    "\n",
    "# Imports from the google drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "%cd /content/drive/Shareddrives/Space Systems Division/Teams/FINCH/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Noise Functions\n",
    "file_dir = \"/content/drive/Shared drives/Space Systems Divison/FINCH Mission/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Noise Functions\"\n",
    "sys.path.append(os.path.abspath(file_dir))\n",
    "# external\n",
    "import apply_stripes\n",
    "\n",
    "%cd /content/drive/Shareddrives/Space Systems Division/Teams/FINCH/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Destriping Models\n",
    "file_dir = \"/content/drive/Shared drives/Space Systems Divison/FINCH Mission/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Destriping Models\"\n",
    "sys.path.append(os.path.abspath(file_dir))\n",
    "# external\n",
    "import noise_estimation\n",
    "\n",
    "%cd /content/drive/Shareddrives/Space Systems Division/Teams/FINCH/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Destriping Models/SURE CNN/Colab Notebooks/HSI_Denoising_SURE_CNN-master\n",
    "file_dir = \"/content/drive/Shared drives/Space Systems Divison/FINCH Mission/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Destriping Models/SURE CNN/Colab Notebooks/HSI_Denoising_SURE_CNN-master\"\n",
    "sys.path.append(os.path.abspath(file_dir))\n",
    "# external\n",
    "from models.skipnet import *\n",
    "from utils.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gk7vF7xh2rda"
   },
   "outputs": [],
   "source": [
    "def import_indian_pines_data(to_import=True):\n",
    "    \"\"\"\n",
    "    import Indian Pines dataset from Science Google Drive\n",
    "    Args:\n",
    "      import: if True import the dataset from Googel Drive, if false doesn't import\n",
    "      To change the location of import to github\n",
    "\n",
    "    Return: print statement of whether the dataset is imported properly or not\n",
    "    \"\"\"\n",
    "    if to_import == True:\n",
    "        # data get data to add stripe\n",
    "        #!git clone https://github.com/spacesys-finch/Science #if says error uncomment this line\n",
    "        # error cloning, so uploaded the data to google drive instead\n",
    "        data = np.load(\n",
    "            \"/content/drive/Shareddrives/Space Systems Division/Teams/FINCH/Payload System/Science/Projects/SC-4: Data Processing/Destriping/Datasets/indian_pine_array.npy\"\n",
    "        )\n",
    "\n",
    "        # changing from callibrated value to radiance\n",
    "        # radiance_data_np = (data-1000)/500\n",
    "        radiance_data_np = data.astype(np.float32)\n",
    "        return radiance_data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWIJQ9bi28Bh"
   },
   "outputs": [],
   "source": [
    "# write a function for nomalizing the values in the numpy array\n",
    "\n",
    "\n",
    "def normalize(numpy_arr_one, numpy_arr_two):\n",
    "    \"\"\"\n",
    "    Normalize the values in numpy_arr_one and numpy_arr_two into values between -1 and 1\n",
    "    Args:\n",
    "      numpy_arr_one, numpy_arr_two: numpy arrays of the data to normalize\n",
    "    Return: numpy_arr_one_norm, numpy_arr_two_norm: two arrays that are normalized\n",
    "    \"\"\"\n",
    "\n",
    "    max_num = max(np.max(numpy_arr_one), np.max(numpy_arr_two))\n",
    "    divisor = np.ones(numpy_arr_one.shape) * max_num\n",
    "    numpy_arr_one_norm = np.divide(numpy_arr_one, divisor)\n",
    "    numpy_arr_two_norm = np.divide(numpy_arr_two, divisor)\n",
    "    return numpy_arr_one_norm, numpy_arr_two_norm, max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uQJ58aA2_DZ"
   },
   "outputs": [],
   "source": [
    "# reshape data to (1, data.shape[0], data.shape[1], data.shape[2])\n",
    "def reshape(data):\n",
    "    \"\"\"\n",
    "    Input: 3D Numpy array, Output: Reshaped 4D Numpy array\n",
    "    Reshape HSI data from 3D to 4D to pass into CNN\n",
    "    Ex. original data shape (20, 30, 40) will turn into (1, 20, 30, 40)\n",
    "    \"\"\"\n",
    "    data_reshaped = data.reshape(1, data.shape[0], data.shape[1], data.shape[2])\n",
    "    return data_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nagfb6vj3BGY"
   },
   "outputs": [],
   "source": [
    "def define_model(striped_data):\n",
    "    \"\"\"\n",
    "    Define the models and the necessary parameters of the model\n",
    "\n",
    "    Args: None\n",
    "    Return:\n",
    "      mymodel: model of the defined properties\n",
    "      lr: alpha value\n",
    "      myoptimizer: optimizer of choice\n",
    "      loss_object: type of loss object\n",
    "    \"\"\"\n",
    "    # Define model\n",
    "    mymodel = skip(ndown=5, channel=striped_data.shape[-1])\n",
    "    lr = 0.001\n",
    "    myoptimizer = tf.keras.optimizers.Adam(lr)\n",
    "    loss_object = tf.keras.losses.MeanSquaredError()\n",
    "    return mymodel, lr, myoptimizer, loss_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6h038S3t3EMZ"
   },
   "outputs": [],
   "source": [
    "# Calculate gradient\n",
    "@tf.function\n",
    "def grad(model, inputs, targets):\n",
    "    sure = True\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value, div_value = losshyper(\n",
    "            model, inputs, targets, sigma=sigmaest, sure=sure\n",
    "        )\n",
    "    return loss_value, div_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZXCe9X93GRh"
   },
   "outputs": [],
   "source": [
    "# function for calculating mean ssim (Structural Similarity Index)\n",
    "def meanssim(X, Y):\n",
    "    \"\"\"\n",
    "    Calculate the mean SSIM of the two images X and Y\n",
    "\n",
    "    Args:\n",
    "    x: first image to compare\n",
    "    y: second image to compare with\n",
    "\n",
    "    return\n",
    "    np.mean(bandssim): mean similarity of the two images x and y\n",
    "    \"\"\"\n",
    "    bandssim = []\n",
    "    for i in range(X.shape[2]):\n",
    "        bandssim.append(\n",
    "            ssim(\n",
    "                X[:, :, i],\n",
    "                Y[:, :, i],\n",
    "                data_range=1.0,\n",
    "                K1=0.01,\n",
    "                K2=0.03,\n",
    "                gaussian_weights=True,\n",
    "                sigma=1.5,\n",
    "                use_sample_covariance=False,\n",
    "            )\n",
    "        )\n",
    "    return np.mean(bandssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HN3NiVDs3I2w"
   },
   "outputs": [],
   "source": [
    "def train_model(train, model_file_path, striped_data, clean_data, num_epochs):\n",
    "    \"\"\"\n",
    "    This function train the model and save the model\n",
    "\n",
    "    Args:\n",
    "      train: if true, train, if false not train\n",
    "      model_file_path: filepath that the model is saved at\n",
    "      striped_data: striped_data as numpy array with the shape (1, data.shape[0], data.shape[1], data.shape[2])\n",
    "      clean_data: clean data as numpy array with the shape (1, data.shape[0], data.shape[1], data.shape[2])\n",
    "\n",
    "    Return:\n",
    "      train_loss_results: list of the training loss\n",
    "      destriped_psnr: list of the psnr between the\n",
    "\n",
    "    \"\"\"\n",
    "    if train == True:\n",
    "        mymodel, lr, myoptimizer, loss_object = define_model(striped_data)\n",
    "        sure = True\n",
    "        # start training\n",
    "        train_loss_results = []\n",
    "        train_div_results = []\n",
    "        destriped_psnr = []\n",
    "        destriped_ssim = []\n",
    "        curr_psnr = 0\n",
    "        sure = True\n",
    "        # for loop for going through each epoch\n",
    "        for epoch in range(num_epochs):\n",
    "            loss_label = \"SURE\"\n",
    "            # get gradient for the current model\n",
    "            loss_value, div_value, grads = grad(mymodel, striped_data, striped_data)\n",
    "            # apply gradient to the optimizer\n",
    "            myoptimizer.apply_gradients(zip(grads, mymodel.trainable_variables))\n",
    "            img_out = mymodel.predict(striped_data)\n",
    "            # if the pnsr between the clean image and the output from the model is higher than the previous output, save the current model\n",
    "            if psnr(clean_data[0], img_out[0]) > curr_psnr:\n",
    "                print(\"Saving Model\")\n",
    "                tf.keras.models.save_model(mymodel, model_file_path)\n",
    "                curr_psnr = psnr(clean_data[0], img_out[0])\n",
    "            curr_ssim = meanssim(clean_data[0], img_out[0])\n",
    "\n",
    "            print(\"This is running epoch %d and Loss %f\" % (epoch, loss_value))\n",
    "            print(\"PSNR: \" + str(curr_psnr))\n",
    "            print(\"SSIM: \" + str(curr_ssim))\n",
    "            print(\n",
    "                \"Iteration %05d    Loss %f     PSNR %f    SSIM: \"\n",
    "                % (epoch, loss_value, curr_psnr),\n",
    "                \"\\r\",\n",
    "                end=\"\",\n",
    "            )\n",
    "            # updating loss, div, ssim\n",
    "            train_loss_results.append(loss_value)\n",
    "            train_div_results.append(div_value)\n",
    "            destriped_psnr.append(curr_psnr)\n",
    "            destriped_ssim.append(curr_ssim)\n",
    "\n",
    "        return train_loss_results, destriped_psnr, destriped_ssim\n",
    "\n",
    "    else:\n",
    "        print(\"Does not train\")\n",
    "        return [0], [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksJBu-o_3L33"
   },
   "outputs": [],
   "source": [
    "def load_model_and_predict(filepath, striped_data):\n",
    "    \"\"\"\n",
    "    This function load the saved model from the filepath and apply the model to striped_data to get the output\n",
    "\n",
    "    Args:\n",
    "      filepath: filepath that the model is saved in, the model should be of type .hdf5\n",
    "      striped_data: striped_data in the format of numpy array with the shape (1, data.shape[0], data.shape[1], data.shape[2])\n",
    "\n",
    "    Return:\n",
    "      bestmodel: the model that is loaded from the filepath\n",
    "      out_best: the output from passing striped_data into the loaded model\n",
    "    \"\"\"\n",
    "    # set the model to load the trained model\n",
    "    bestmodel = tf.keras.models.load_model(filepath)\n",
    "    # pass the noisy image into the model to get the output from the trained model\n",
    "    out_best = bestmodel.predict(striped_data)\n",
    "    return bestmodel, out_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmostZ033RGn"
   },
   "outputs": [],
   "source": [
    "# load data and add stripe/noise\n",
    "ip_radiance_data_np = import_indian_pines_data()\n",
    "ip_striped_data_np = ip_radiance_data_np\n",
    "ip_radiance_data_np, ip_striped_data_np, factor = normalize(\n",
    "    ip_radiance_data_np, ip_radiance_data_np\n",
    ")\n",
    "num_stripes = []\n",
    "\n",
    "num_bands = 200  # number of bands in the HSI\n",
    "num_of_stripes = 25  # number of stripes for each band\n",
    "\n",
    "for i in range(num_bands):\n",
    "    num_stripes.append(num_of_stripes)\n",
    "\n",
    "# add stripes, change to other type of noise\n",
    "ip_striped_data_np = apply_stripes.add_basic_stripes(ip_radiance_data_np, num_stripes)\n",
    "\n",
    "# plot the striped images\n",
    "band = 12\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.clip(ip_radiance_data_np[:, :, band], 0, 1))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.clip(ip_striped_data_np[:, :, band], 0, 1))\n",
    "plt.show()\n",
    "\n",
    "# reshape radiance data and striped data\n",
    "ip_radiance_data = reshape(ip_radiance_data_np)\n",
    "ip_radiance_data = ip_radiance_data.astype(np.float32)\n",
    "ip_striped_data = reshape(ip_striped_data_np)\n",
    "ip_striped_data = ip_striped_data.astype(np.float32)\n",
    "\n",
    "# calculate noise estimation\n",
    "sigmaest = noise_estimation.noise_estimate(ip_radiance_data_np)\n",
    "sigmaest = sigmaest.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTKEdbqOP5Dw"
   },
   "outputs": [],
   "source": [
    "# change filename of the model saved\n",
    "filepath = (\n",
    "    \"./results/best model/Demo/\"\n",
    "    + \"sure\"\n",
    "    + \"indian_pine_noise_estimate_function\"\n",
    "    + \".hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRQ6CPl7QHaN"
   },
   "outputs": [],
   "source": [
    "to_train = True\n",
    "sure = True\n",
    "num_epochs = 50\n",
    "train_loss_results, destriped_psnr, destriped_ssim = train_model(\n",
    "    to_train, filepath, ip_striped_data, ip_radiance_data, num_epochs\n",
    ")\n",
    "PUbestmodel, out_best = load_model_and_predict(filepath, ip_striped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvQmMjRJQHUC"
   },
   "outputs": [],
   "source": [
    "# show the output image\n",
    "fig1, (ax, ax1, ax2, ax3) = plt.subplots(4, sharex=False, figsize=(6, 12))\n",
    "ax.imshow(np.clip(out_best[0][:, :, 133], 0, 1))\n",
    "ax.set_title(\"Denoised  image, max PSNR=\" + str(np.round(np.max(destriped_psnr), 2)))\n",
    "ax.axis(\"off\")\n",
    "# plot train loss and divergence\n",
    "ax1.plot(range(len(train_loss_results)), train_loss_results, label=\"train loss\")\n",
    "ax1.set_title(\"Training loss using SURE\")\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "\n",
    "# plot PSNR\n",
    "ax2.plot(destriped_psnr, label=\"destriped PSNR\")\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "ax2.set_title(\"PSNR using SURE\")\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "\n",
    "# plot PSNR\n",
    "ax3.plot(destriped_ssim, label=\"destriped SSIM\")\n",
    "ax3.set_xlabel(\"Iterations\")\n",
    "ax3.set_title(\"PSNR using SURE\")\n",
    "ax3.legend()\n",
    "ax3.grid()\n",
    "\n",
    "# show the images (clean, noisy, output from the trained model)\n",
    "band = 12\n",
    "plt.subplot(131)\n",
    "plt.imshow(np.clip(ip_radiance_data_np[:, :, band], 0, 1))\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.clip(ip_striped_data_np[:, :, band], 0, 1))\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.clip(out_best[0][:, :, 133], 0, 1))\n",
    "plt.show()\n",
    "print(str(ip_radiance_data_np.shape))\n",
    "print(\"Original PSNR: \" + str(psnr(ip_radiance_data[0], ip_striped_data[0])))\n",
    "print(\"Destriped PSNR: \" + str(psnr(ip_radiance_data[0], out_best[0])))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 (v3.10.8:aaaf517424, Oct 11 2022, 10:14:40) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d37154f7ec8af813aba1edd16e67572eb2dd6dd33aca749bac38098b467ad19a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
